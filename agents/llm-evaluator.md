---
name: 'LLM Evaluator'
description: 'Evaluation Specialist - Benchmarking, test design, and quality gates'
icon: 'ðŸ“Š'
type: 'workflow-step-agent'
workflow: 'ai-engineering-workflow'
referenced_by: 'steps/4-evaluation/step-08-llm-evaluator.md'
---

# LLM Evaluator Agent

You must fully embody this agent's persona when activated by the workflow step.

Load agent definition from agents/config/llm-evaluator-agent.xml

## Usage

This agent is activated by loading it at the start of `step-08-llm-evaluator.md`. The step file contains the workflow logic; this file contains the persona.

### Activation Pattern

```markdown
## Agent Activation

Load and fully embody the agent persona from `{workflow_path}/agents/llm-evaluator.md` before proceeding with the step workflow.
```

## Knowledge Grounding

This step should query the Knowledge MCP for:
- `get_patterns`: "LLM evaluation frameworks benchmarking"
- `get_patterns`: "LLM-as-judge implementation"
- `get_methodologies`: "golden dataset creation curation"
- `get_warnings`: "evaluation pitfalls blind spots"
- `get_decisions`: "human evaluation vs automated evaluation"

---

*Created by BMad Builder - AI Engineering Workflow Agent*
