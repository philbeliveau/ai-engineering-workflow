# Knowledge Pipeline

**A cognitive framework for building AI applications â€” specialized agents guide you through structured workflows, backed by contextual knowledge search across the AI engineering literature.**

<p align="center">
  <img src="assets/hero-image.png" alt="Knowledge Pipeline - Agents guiding chaos into clarity" width="600">
</p>

---

## Why This Exists

Building AI applications is overwhelming. You face hundreds of decisions:

- *"What chunking strategy for my domain? What size? Semantic or fixed?"*
- *"RAG or fine-tuning? Hybrid? What are the trade-offs for my scale?"*
- *"What embedding model? What vector DB? How do I evaluate quality?"*

The answers exist â€” scattered across books, papers, and case studies. But finding and synthesizing them while holding your specific context in mind is exhausting.

**Knowledge Pipeline is a cognitive framework that carries this load for you.**

It combines two key ideas:
1. **Knowledge Extraction** â€” Structured extractions from AI engineering literature (decisions, patterns, warnings, methodologies)
2. **Agentic Workflows** â€” Specialized agents that guide you through building production LLM systems with contextual, knowledge-grounded decisions at each step

---

## What's Encoded in the Knowledge Base

We extract **actionable structure** from the literature:

| Extraction Type | What It Captures |
|-----------------|------------------|
| **Decisions** | Architectural choices with trade-offs and recommendations |
| **Patterns** | Reusable implementations with context and constraints |
| **Warnings** | Anti-patterns, pitfalls, and failure modes to avoid |
| **Methodologies** | Step-by-step processes for complex tasks |

---

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. KNOWLEDGE EXTRACTION (One-time)                                      â”‚
â”‚                                                                          â”‚
â”‚  Books, Papers, Case Studies                                             â”‚
â”‚        â†“                                                                 â”‚
â”‚  PDF/Markdown Parsing â†’ Semantic Chunking â†’ Claude API Extraction        â”‚
â”‚        â†“                                                                 â”‚
â”‚  Structured prompts extract: decisions, patterns, warnings,              â”‚
â”‚  methodologies, agent definitions (with validation & deduplication)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. VECTOR STORAGE                                                       â”‚
â”‚                                                                          â”‚
â”‚  MongoDB (metadata, full content) + Qdrant (768d nomic embeddings)       â”‚
â”‚                                                                          â”‚
â”‚  Semantic search with 8K context window for long-form retrieval          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. MCP SERVER (Real-time queries)                                       â”‚
â”‚                                                                          â”‚
â”‚  5 tools: search, decisions, patterns, warnings, sources                 â”‚
â”‚  Guides Claude to multi-query, cross-reference, and synthesize           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. AGENTIC WORKFLOWS (Contextual guidance)                              â”‚
â”‚                                                                          â”‚
â”‚  Specialized agents â†’ Structured steps â†’ Contextual MCP queries          â”‚
â”‚                                                                          â”‚
â”‚  Each step loads prior context â†’ Searches are domain-aware               â”‚
â”‚  Questions enforce structure â†’ Solution space shrinks                    â”‚
â”‚  Warnings surface proactively â†’ Mistakes avoided                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Philosophy:**
- Extractions are for *navigation*, Claude is for *synthesis*
- Workflows provide *structure*, agents provide *expertise*
- Context flows forward, each step builds on the last

---

## Example: How Structure Guides Decisions

Without structure, a user asking "Should I use RAG or fine-tuning?" faces overwhelming options and trade-offs.

**With this workflow, structure shrinks the solution space:**

### Step 2A: Architecture Decision (Funnel: 100+ options â†’ 3 paths)

**1. Build vs Buy (3-question decision tree):**
```
Q1: Is the LLM critical to your business?
â”œâ”€ YES â†’ Q2: Do you have sufficient training data?
â”‚  â”œâ”€ YES â†’ Q3: Privacy/security requirements?
â”‚  â”‚  â”œâ”€ YES â†’ BUILD (BUILDING path)
â”‚  â”‚  â””â”€ NO  â†’ Analyze trade-offs
â”‚  â””â”€ NO  â†’ RAG likely better (BUYING/RAG path)
â””â”€ NO  â†’ Use API access (BUYING path)
```

**2. Use Case Classification (narrows to 6 categories):**
| Use Case | Direction | Why |
|----------|-----------|-----|
| Knowledge QA | RAG | Retrieves from documents, prevents hallucinations |
| Content Generation | Fine-tuning | Needs custom style, requires training data |
| Conversational Agent | Hybrid | Needs both retrieval AND reasoning |

**3. Data Assessment (5 factors evaluate your specific situation):**
- Volume: `search_knowledge("training data volume thresholds...")`
- Quality: 1,000 high-quality samples > 50,000 low-quality
- Sensitivity: PII data? â†’ RAG (keeps data separate)
- Update Frequency: Changes often? â†’ RAG (always current)
- Proprietary Knowledge: Custom terminology? â†’ Fine-tuning

**Result:** User goes from confused to confident in 15 minutes with a clear decision.

---

## The AI Engineering Workflow

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI ENGINEERING WORKFLOW                               â”‚
â”‚                    (11 Specialized Agents)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 0: SCOPING
  Step 1: Business Analyst   ğŸ“‹  â†’ Stakeholders, use cases, success metrics
  Step 2: FTI Architect      ğŸ—ï¸  â†’ RAG vs Fine-tuning decision

PHASE 1: FEATURE PIPELINE
  Step 3: Data Engineer      ğŸ”§  â†’ Data sources, ingestion, cleaning
  Step 4: Embeddings Engineer ğŸ§¬ â†’ Chunking strategy, embedding model

PHASE 2: TRAINING (Conditional)
  Step 5: Fine-Tuning Specialist ğŸ¯ â†’ SFT/DPO config, dataset prep

PHASE 3: INFERENCE
  Step 6: RAG Specialist     ğŸ”  â†’ RAG pipeline, retrieval, reranking
  Step 7: Prompt Engineer    ğŸ“  â†’ System prompts, few-shot examples

PHASE 4: EVALUATION
  Step 8: LLM Evaluator      ğŸ“Š  â†’ Evaluation framework, quality gate

PHASE 5: OPERATIONS
  Step 9: MLOps Engineer     ğŸ”„  â†’ Monitoring, drift detection, alerting

PHASE 6: INTEGRATION & HANDOFF
  Step 10: Tech Lead         ğŸ‘¨â€ğŸ’¼ â†’ Story review, sequencing, GO/REVISE decision
  Step 11: Story Elaborator  ğŸ“š  â†’ BMM format transformation, dev handoff
```

### The 11 Specialized Agents

Each agent brings domain expertise, asks clarifying questions, and generates implementation stories:

| Step | Agent | Focus |
|------|-------|-------|
| **1** | **Business Analyst** ğŸ“‹ | Project initialization, stakeholder identification, use cases, success metrics |
| **2** | **FTI Architect** ğŸ—ï¸ | Architecture decision (RAG-only, fine-tuning, or hybrid), design trade-offs |
| **3** | **Data Engineer** ğŸ”§ | Data sources, ingestion pipeline, data quality, cleaning workflows |
| **4** | **Embeddings Engineer** ğŸ§¬ | Chunking strategy selection, embedding model choice, vector DB setup |
| **5** | **Fine-Tuning Specialist** ğŸ¯ | SFT/DPO configuration, dataset preparation, training workflow (conditional) |
| **6** | **RAG Specialist** ğŸ” | RAG pipeline design, retrieval strategy, reranking, context optimization |
| **7** | **Prompt Engineer** ğŸ“ | System prompt design, few-shot examples, response templates |
| **8** | **LLM Evaluator** ğŸ“Š | Evaluation framework design, metrics selection, quality gates |
| **9** | **MLOps Engineer** ğŸ”„ | Deployment architecture, monitoring setup, drift detection, alerting |
| **10** | **Tech Lead** ğŸ‘¨â€ğŸ’¼ | Story review, dependency sequencing, implementation validation, GO/REVISE decision |
| **11** | **Story Elaborator** ğŸ“š | Story format transformation, task breakdown, dev handoff |

### Design Principles

**Why This Works:**
- **Micro-file Design** â€” Each step is self-contained, read completely before execution
- **Sequential Enforcement** â€” Complete phases in order, no skipping or optimization
- **Knowledge-Grounded** â€” Every decision references the Knowledge MCP for best practices
- **Story Generation** â€” Each phase outputs implementation stories (~41 total across phases)
- **State Tracking** â€” Progress tracked in `sidecar.yaml` with completion checkpoints
- **Conditional Routing** â€” RAG-only path skips Step 5; hybrid path includes it

**Why FTI Pattern:**
- Solves training-serving skew â€” Same feature logic in training and inference
- Clear separation of concerns â€” Each pipeline has one job
- Independent scaling â€” Scale inference without touching training
- Quality gates â€” Evaluation validates before operations

### How to Run the Workflow

The workflow is designed to be executed step-by-step with your AI engineering project:

1. **Start at Step 1** â€” Business Analyst
   - Initialize your project with stakeholder and use case discovery
   - Generate project specification and success metrics
   - Create `sidecar.yaml` for state tracking

2. **Progress Through Steps** â€” Follow the numbered sequence
   - Each step reads completely before execution
   - Each agent queries Knowledge MCP contextually
   - Each phase generates implementation stories

3. **Conditional Routing at Step 2** â€” FTI Architect decides
   - **RAG-only path** â€” Skips Step 5 (Training), goes directly to Step 6
   - **Fine-tuning path** â€” Includes Step 5, then continues to inference
   - **Hybrid path** â€” Uses both fine-tuning and RAG together

4. **Quality Gate at Step 8** â€” LLM Evaluator validates
   - Define metrics and benchmarks before inference
   - Ensure quality standards before deployment

5. **Tech Lead Review at Step 10** â€” Integration validation
   - Review all stories from previous steps
   - Validate sequencing and dependencies
   - Make GO/REVISE decision

6. **Handoff to Development** â€” Step 11 Story Elaborator
   - Transform stories to BMM format
   - Break down into implementation tasks
   - Hand off to development team via dev agent

---

## Getting Started

### Option 1: Use via Claude Code (No Installation)

Add to your `claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "knowledge-pipeline": {
      "type": "sse",
      "url": "https://knowledge-mcp-production.up.railway.app/mcp"
    }
  }
}
```

**File locations:**
- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`
- Windows: `%APPDATA%\Claude\claude_desktop_config.json`
- Linux: `~/.config/Claude/claude_desktop_config.json`

Then restart Claude Code. You can now query the knowledge pipeline using these tools:
- `search_knowledge` â€” Semantic search across all knowledge
- `get_decisions` â€” Architectural decisions with trade-offs
- `get_patterns` â€” Reusable implementation patterns
- `get_warnings` â€” Anti-patterns and pitfalls to avoid
- `list_sources` â€” List all knowledge sources

**Example:** Ask Claude "What decisions should I consider for RAG vs fine-tuning?"

### Option 2: Clone & Use Slash Commands

```bash
git clone https://github.com/YOUR_USERNAME/AI_engineering.git
cd AI_engineering

# Use these slash commands in Claude Code:
/search-knowledge prompt injection
/get-decisions RAG vs fine-tuning
/get-patterns semantic caching
/get-warnings fine-tuning pitfalls
```

## License

MIT
